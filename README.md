# ğŸš† ETL Transport IntercitÃ©s â€“ Data Engineering Project

Ce projet met en Å“uvre un pipeline ETL complet pour collecter, transformer et charger des donnÃ©es de rÃ©gularitÃ© des trains IntercitÃ©s (SNCF), en s'appuyant sur une stack open source professionnelle.

---

## ğŸ› ï¸ Stack utilisÃ©e

* **PostgreSQL** : stockage relationnel des donnÃ©es
* **Apache Airflow** : orchestration des Ã©tapes ETL
* **Docker Compose** : environnement de dÃ©veloppement reproductible
* **Python (pandas, SQLAlchemy)** : transformation et chargement des donnÃ©es

---

## ğŸ“Š Source des donnÃ©es

* DonnÃ©es issues du portail officiel SNCF :
  [https://data.sncf.com/explore/dataset/regularite-mensuelle-intercites](https://data.sncf.com/explore/dataset/regularite-mensuelle-intercites)
* Format : CSV mensuel
* DonnÃ©es depuis janvier 2014

---

## ğŸ—‚ï¸ Structure du projet

```
.
â”œâ”€â”€ dags/               # DAG Airflow (etl_transport.py)
â”œâ”€â”€ etl/                # Scripts extract / transform / load
â”œâ”€â”€ db/                 # SchÃ©ma SQL
â”œâ”€â”€ data/               # Fichiers CSV et Parquet
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## âš™ï¸ Lancer le projet en local

### 1. DÃ©marrer lâ€™environnement

```bash
docker-compose up -d
```

### 2. AccÃ©der Ã  Airflow

* Interface : [http://localhost:8080](http://localhost:8080)
* Identifiant : `admin` / Mot de passe : `admin`

### 3. Lancer le pipeline

* Activer le DAG `etl_transport_data`
* Cliquer sur "Trigger DAG"
* Suivre l'exÃ©cution dans les logs (extract â†’ transform â†’ load)

---

## ğŸ’¡ Fonctions principales

* `download_transport_data(url, path)` : tÃ©lÃ©charge le fichier CSV brut
* `clean_transport_data(csv_path)` : nettoie les donnÃ©es, calcule les ratios
* `load_dataframe_to_postgres(df, db_url, schema_path)` : charge dans PostgreSQL
* Le DAG appelle ces fonctions via Airflow, avec passage des donnÃ©es par fichier `.parquet`

---

## ğŸ“Œ Ã€ venir

* ğŸ”„ IntÃ©gration de donnÃ©es mÃ©tÃ©o pour analyse croisÃ©e
* ğŸ“Š Ajout dâ€™Apache Superset pour visualiser les retards
* ğŸ” DÃ©ploiement continu avec Airflow + cron

---

## âœï¸ Auteur

Marko Macanovic
